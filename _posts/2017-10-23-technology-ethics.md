---
layout: post
title: The Ethics of Technological Progress
date: 2017-10-23
---
As witnesses to, and sometimes participants in, the great strides made in computer science today, we find ourselves faced with questions. Sometimes, the question of "What new and inventive things can we do with technology?" raises another, more complicated question: "What are the ethical ramifications?" 

One complaint that I have with the field of tech is the lackadaisical attitude that some of its pioneers take when it comes to ethical questions. More and more these days I see pushback against people who have these concerns. They are accused of being old-fashioned, asked to change their very conception of what is ethical, told that the ends (personalized commercials) justify the means (violations of privacy), and so on. <a href="https://www.huffingtonpost.com/2010/04/29/zuckerberg-privacy-stance_n_556679.html">Consider the controversy that came out of Mark Zuckerberg's supposedly cavalier attitude towards Facebook users' privacy.</a> The fact that people are urged to be complacent about these things, are told that they are a necessary part of "getting with the times," should at least give us pause.

Our reading set this week gave us examples of interesting, and sometimes problematic, advances in computer science. For instance, there was the <a href="http://www.npr.org/2016/10/23/499042369/police-facial-recognition-databases-log-about-half-of-americans">NPR article</a>  about the inclusion of DMV driver's license photographs in police facial recognition databases. While this obviously increases the chances of identifying perpetrators of crimes, the additional possibility of implicating innocent people in those crimes is disturbing. Are people informed that their photographs might be used in such a way when they obtain their licenses? And how accurate is facial recognition technology really?

We also read <a href="https://www.economist.com/news/science-and-technology/21728614-machines-read-faces-are-coming-advances-ai-are-used-spot-signs">an article published by The Economist called "Advances in AI are used to spot signs of sexuality."</a> Stanford University's Drs. Michal Kosinski and Yilun Wang have developed an AI system that can "infer sexual orientation by analysing peope's faces" with some accuracy. The ethics of this project are obviously questionable; this became all the more apparent to me when Dr. Kosinski was quoted as saying, "With the right data setsâ€¦similar AI systems might be trained to spot other intimate traits, such as <b>IQ or political views</b> [emphasis mine]." This statement alone is hugely problematic: The AI program in question relies on an analysis of biological characteristics to make its inferences, so Dr. Kosinski is implying that IQ (the ability to "measure" which, or even the legitimacy of which, is contested anyway) correlates in some way to phenotype. I am reminded immediately of the kinds of "inferences" scientists claimed they could make under the auspices of eugenics and scientific racism; and though Dr. Kosinski himself does not seem to have this intent, others might. As is mentioned in the article itself, there are "dangers" involved with the technology: "In parts of the world where being gay is socially unacceptable, or illegal, such software could pose a serious threat to safety."

Finally, Dr. Kosinski's warning that "further erosion of privacy [is] 'inevitable'" might seem to absolve us of any future ethical responsibility for our technology. I disagree with his statement. The article mentions that Dr. Kosinski "has invented no new technology, merely bolted together software and data that are readily available to anyone with an internet connection"; and while this does show the inevitability (and ubiquity) of technological progress, it does not serve as a reason why we should abandon our ethical principles. 
